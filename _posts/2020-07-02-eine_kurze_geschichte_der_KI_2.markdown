---
layout: post
title:  "Eine kleine Geschichte der künstlichen Intelligenz - Teil 2"
date:   2020-07-02 11:30:04 +0100
categories: KI Allgemein
---

<!-- Mathjax Support -->
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

Bevor Du startest mit lesen, mach Dich schnell im [Prolog]({{ site.baseurl }}{% link _posts/2020-05-02-proglog.markdown %}) schlau.

### Wiedergeburt

$$ \_\Lambda\_:$$  
Hast Du Fragen? Du schaust ein wenig belämmert in die Welt? Hast Du genug Wasser
getrunken? Du bist ein wenig bleich.

$$ \_m\_:$$   
Also ehrlich. Hör auf mich immer zu bemuttern. Ja, ich trinke ja Wasser. Aber erzähl, wie ging es weiter.

$$ \_\Lambda\_:$$  
In den 80er und 90er Jahren hat man erkannt, dass Methoden aus den Bereichen stochastische Modellierung,
Spieltheorie, Operational Research, genetische Algorithmen etc. die Genauigkeit und Robustheit von KI Systemen
verbessern. Erste, brauchbare neuronale Netze erblickten die Welt und ein realistisches Expectation Management
gaben dem Forschungsgebiet KI neuen Auftrieb.

$$ \_m\_:$$  
Neuronale Netze, genau. Das ist der hot-shit. Jetzt kommen wir der Sache schon näher. Bitte mehr darüber.


$$ \_\Lambda\_:$$  
Darüber werden wir später sprechen. Wie du aber jetzt schon siehst, sind neuronale Netze keine neue Erfindung.
Die mathematische Beschreibung dafür gibt es schon sehr lange. Durch neuere Hardware und die Masse an Daten, auf
die man jetzt zugreifen konnte, konnte man diese Netze vernünftig aufsetzen und trainieren.

$$ \_m\_:$$  
Oh je. Die Geschichtsstunde dauert an.

$$ \_\Lambda\_:$$  
So ist es. Iss mal ne Frucht. Das macht das Hirn frischer.

$$ \_m\_:$$  
Warst Du in Deinem früheren Leben ein Ernährungs-Berater-Roboter? Ich mag lieber ein Bier.

$$ \_\Lambda\_:$$  
Zwecklos und hoffnungslos. Wer bezahlt eigentlich die Kosten, wenn Du alt bist und verwelkst?
Schon mal darüber nachgedacht? Also, lass uns weitermachen.

In den Jahren 1983 und 2010 wurde die Hardware viel billiger und mehr als 500.000 Mal schneller; für viele Probleme reichte jedoch ein Computer immer noch nicht aus, um viele Algorithmen des maschinellen Lernens in angemessener Zeit auszuführen. Auf theoretischer Ebene hatte die Informatikforschung in den Jahren 1950-2000 gezeigt, dass solche Probleme viel schneller gelöst werden konnten, wenn viele Computer gleichzeitig und verteilt eingesetzt wurden. Die folgenden grundlegenden Probleme im Zusammenhang mit dem verteilten Rechnen blieben jedoch bis 2003 gelöst: (a) wie man Berechnungen parallelisiert, (b) wie man Daten "gerecht" auf die Computer verteilt und einen automatischen Lastausgleich vornimmt, und (b) wie man mit Computerausfällen umgeht und sie unterbricht, wenn sie in Endlosschleifen geraten. Im Jahr 2003 veröffentlichte Google das Google File Systems Paper und veröffentlichte 2004 MapReduce, ein Framework und eine zugehörige Implementierung zur Verarbeitung und Erzeugung großer Datensätze mit einem parallelen, verteilten Algorithmus auf einem Cluster [68]. Da MapReduce Eigentum von Google war, schufen Cutting und Carafella (von der University of Washington) im Jahr 2006 eine quelloffene und freie Version dieses Frameworks namens Hadoop [69]. Außerdem wurden 2012 Spark und seine robusten verteilten Datensätze erfunden, die die Latenz vieler Anwendungen im Vergleich zu MapReduce und Hadoop-Implementierungen reduzierten [70]. Heute kann eine auf Hadoop-Spark basierende Infrastruktur 100.000 oder mehr Computer und mehrere hundert Millionen Gigabyte Speicherplatz bewältigen.




**Referenzen**  

[1] Minsky, Marvin (1967), "Computation: finite and infinite machines," Prentice-Hall, Inc. page 2. ISBN:0-13-165563-9.

[2] "AI pioneer Marvin Minsky dies aged 88". BBC News. 26 January 2016.
