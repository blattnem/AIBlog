---
layout: post
title:  "Eine kleine Geschichte der künstlichen Intelligenz - Teil 2"
date:   2020-07-02 11:30:04 +0100
categories: KI Allgemein
---

<!-- Mathjax Support -->
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

Bevor Du startest mit lesen, mach Dich schnell im [Prolog]({{ site.baseurl }}{% link _posts/2020-05-02-proglog.markdown %}) schlau.

### Wiedergeburt

$$ \_\Lambda\_:$$  
Hast Du Fragen? Du schaust ein wenig belämmert in die Welt? Hast Du genug Wasser
getrunken? Du bist ein wenig bleich.

$$ \_m\_:$$   
Also ehrlich. Hör auf mich immer zu bemuttern. Ja, ich trinke ja Wasser. Aber erzähl, wie ging es weiter.

$$ \_\Lambda\_:$$  
In den 80er und 90er Jahren hat man erkannt, dass Methoden aus den Bereichen stochastische Modellierung,
Spieltheorie, Operational Research, genetische Algorithmen etc. die Genauigkeit und Robustheit von KI Systemen
verbessern. Erste, brauchbare neuronale Netze erblickten die Welt und ein realistisches Expectation Management
gaben dem Forschungsgebiet KI neuen Auftrieb.

$$ \_m\_:$$  
Neuronale Netze, genau. Das ist der hot-shit. Jetzt kommen wir der Sache schon näher. Bitte mehr darüber.


$$ \_\Lambda\_:$$  
Darüber werden wir später sprechen. Wie du aber jetzt schon siehst, sind neuronale Netze keine neue Erfindung.
Die mathematische Beschreibung dafür gibt es schon sehr lange. Durch neuere Hardware und die Masse an Daten, auf
die man jetzt zugreifen konnte, konnte man diese Netze vernünftig aufsetzen und trainieren.

$$ \_m\_:$$  
Oh je. Die Geschichtsstunde dauert an.

$$ \_\Lambda\_:$$  
So ist es. Iss mal ne Frucht. Das macht das Hirn frischer.

$$ \_m\_:$$  
Warst Du in Deinem früheren Leben ein Ernährungs-Berater-Roboter? Ich mag lieber ein Bier.

$$ \_\Lambda\_:$$  
Zwecklos und hoffnungslos. Wer bezahlt eigentlich die Kosten, wenn Du alt bist und verwelkst?
Schon mal darüber nachgedacht? Also, lass uns weitermachen.


Zwischen 1980 und 2010 hat die Entwicklung von Hardware einen grossen Sprung gemacht und das
Preis-Leistungsverhältnis hat sich immens verbessert. Viele Probleme konnten nun
sinnvoll angegangen werden. Die Möglichkeit mit grossen Datenmengen über verteilte Systeme zu operieren
eröffnete ganz neue Möglichkeiten. Denn im Allgemeinen sind Lernalgorithmen sehr datenhungrig.
Besonders neuronale Netze brauchen sehr viele Daten, um sinnvolle Muster und
Abstraktionen extrahieren zu können.

$$ \_m\_:$$  
Du sagst es schon wieder. Neuronale Netze. Jetzt erklär doch mal was das ist. Bitte kleine
Geschichte mehr.

$$ \_\Lambda\_:$$  
Ok. Ich verspreche. Nur noch ein wenig Geschichte und dann werden wir über Lernalgorithmen
sprechen. Hattest Du Deinen Apfel schon?

$$ \_m\_:$$  
Haha. Nice try. Ich esse einen Apfel, wenn Du über Lernalgorithmen sprichst. Ist das
ein Deal?







**Referenzen**  

[1] Minsky, Marvin (1967), "Computation: finite and infinite machines," Prentice-Hall, Inc. page 2. ISBN:0-13-165563-9.

[2] "AI pioneer Marvin Minsky dies aged 88". BBC News. 26 January 2016.
